{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CazISR8X_HUG"
   },
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOyqYHTk_Q57"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_YHJjnD_Tja"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgC61-ah_WIz"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrxyEKGn_ez7"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Sales forecast final.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data type to int\n",
    "dataset['week no']=dataset['week no'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week no</th>\n",
       "      <th>Category</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>679064.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1268409.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>94744.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>2016</td>\n",
       "      <td>1446.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>1475152.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week no  Category  Year       Sales\n",
       "0       49         2  2016   679064.37\n",
       "1       49         1  2016  1268409.60\n",
       "2       49         5  2016    94744.94\n",
       "3       49        35  2016     1446.67\n",
       "4       49         7  2016  1475152.07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting required columns\n",
    "data=dataset[['week no','Category','Year','Sales']]\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dependant and independant variables\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mp21865\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#encode categorical variables ('category' and 'Year')\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1,2])],remainder='passthrough',sparse_threshold=0)\n",
    "X=np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WemVnqgeA70k"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kb_v_ae-A-20"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling to bring all the variables within a fixed range\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,-1:] = sc.fit_transform(X_train[:,-1:])\n",
    "X_test[:,-1:] = sc.transform(X_test[:,-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-McZVsQBINc"
   },
   "source": [
    "## Training the Multiple Linear Regression model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywPjx0L1BMiD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNkXL1YQBiBT"
   },
   "source": [
    "## Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TQKmwvtdBkyb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28e+06  1.05e+06]\n",
      " [ 1.17e+06  1.05e+06]\n",
      " [ 4.78e+05  6.39e+05]\n",
      " [ 2.09e+06  2.25e+06]\n",
      " [ 9.25e+04  4.00e+01]\n",
      " [ 1.83e+06  1.27e+06]\n",
      " [ 3.00e+05  2.29e+05]\n",
      " [ 2.11e+06  2.21e+06]\n",
      " [-2.62e+05  9.95e+02]\n",
      " [ 2.18e+06  3.66e+06]\n",
      " [ 3.84e+05  3.63e+05]\n",
      " [ 7.37e+04  2.40e+02]\n",
      " [-1.73e+05  4.00e-02]\n",
      " [-3.98e+04  5.05e+04]\n",
      " [ 1.86e+05  1.12e+05]\n",
      " [ 1.90e+06  1.28e+06]\n",
      " [-1.50e+03  3.15e+02]\n",
      " [ 1.98e+06  1.78e+06]\n",
      " [ 2.25e+05  2.60e+05]\n",
      " [ 3.21e+05  2.96e+05]\n",
      " [ 2.65e+05  3.41e+05]\n",
      " [ 5.22e+03  2.38e+02]\n",
      " [ 2.17e+06  2.52e+06]\n",
      " [ 2.08e+06  2.25e+06]\n",
      " [ 5.03e+05  4.31e+05]\n",
      " [ 2.17e+06  1.42e+06]\n",
      " [-7.02e+04  4.58e+02]\n",
      " [ 1.91e+06  1.17e+06]\n",
      " [ 1.76e+06  2.19e+06]\n",
      " [ 2.16e+06  1.01e+06]\n",
      " [ 1.40e+06  1.69e+06]\n",
      " [ 6.70e+04  2.10e+05]\n",
      " [ 5.16e+05  1.40e+05]\n",
      " [ 2.48e+05  9.00e+04]\n",
      " [ 3.73e+05  2.68e+05]\n",
      " [ 2.24e+06  3.82e+06]\n",
      " [ 9.45e+04  1.32e+05]\n",
      " [ 3.65e+05  2.40e+05]\n",
      " [ 1.42e+06  2.35e+06]\n",
      " [ 2.16e+05  2.03e+05]\n",
      " [-2.56e+05  9.18e+02]\n",
      " [ 1.87e+05  2.20e+05]\n",
      " [-1.67e+05  0.00e+00]\n",
      " [ 3.10e+05  2.59e+05]\n",
      " [ 1.78e+05  2.70e+05]\n",
      " [ 3.41e+05  2.29e+05]\n",
      " [ 2.18e+06  3.48e+06]\n",
      " [ 4.54e+05  5.09e+05]\n",
      " [-1.65e+04  3.07e+02]\n",
      " [ 3.54e+05  3.13e+05]\n",
      " [ 2.22e+05  1.97e+05]\n",
      " [ 1.85e+06  1.63e+06]\n",
      " [ 1.95e+06  2.17e+06]\n",
      " [ 3.63e+05  1.77e+05]\n",
      " [ 1.85e+05  2.57e+05]\n",
      " [ 4.24e+04  1.05e+02]\n",
      " [ 3.06e+05  2.35e+05]\n",
      " [ 3.22e+05  1.86e+05]\n",
      " [ 4.72e+05  5.98e+05]\n",
      " [ 2.21e+06  1.19e+06]\n",
      " [-4.21e+03  9.00e+02]\n",
      " [-1.36e+04  1.74e+02]\n",
      " [ 1.93e+06  1.70e+06]\n",
      " [ 2.11e+06  1.41e+06]\n",
      " [ 2.19e+05  2.38e+05]\n",
      " [ 1.30e+06  9.23e+05]\n",
      " [-3.97e+03  6.36e+02]\n",
      " [-3.36e+04  6.00e+04]\n",
      " [ 2.95e+05  1.65e+05]\n",
      " [ 2.20e+06  1.34e+06]\n",
      " [ 1.15e+04  9.84e+01]\n",
      " [ 2.35e+05  2.89e+05]\n",
      " [ 1.88e+06  1.35e+06]\n",
      " [ 4.16e+05  6.61e+05]\n",
      " [ 1.24e+05  5.00e+01]\n",
      " [ 4.00e+05  3.98e+05]\n",
      " [ 2.20e+06  1.61e+06]\n",
      " [ 2.17e+06  4.51e+06]\n",
      " [ 2.11e+05  1.40e+05]\n",
      " [-7.04e+04  5.00e+02]\n",
      " [ 3.75e+05  2.58e+05]\n",
      " [ 1.74e+06  1.22e+06]\n",
      " [ 1.26e+05  1.15e+05]\n",
      " [-2.28e+04  1.46e+02]\n",
      " [ 2.75e+05  1.92e+05]\n",
      " [ 2.23e+05  1.34e+05]\n",
      " [ 3.50e+05  2.44e+05]\n",
      " [ 5.39e+03  9.47e+04]\n",
      " [ 3.94e+05  2.78e+05]\n",
      " [ 3.97e+04 -3.75e+00]\n",
      " [ 1.51e+05  7.57e+04]\n",
      " [ 2.13e+05  1.41e+05]\n",
      " [ 1.99e+06  1.39e+06]\n",
      " [ 2.51e+05  6.26e+04]\n",
      " [ 4.19e+05  3.60e+05]\n",
      " [ 2.21e+06  1.63e+06]\n",
      " [ 2.03e+06  1.43e+06]\n",
      " [ 1.24e+05  1.71e+03]\n",
      " [ 2.76e+05  1.57e+05]\n",
      " [ 4.10e+05  4.00e+05]\n",
      " [ 4.04e+05  6.23e+05]\n",
      " [ 2.10e+06  2.27e+06]\n",
      " [ 1.72e+05  2.40e+05]\n",
      " [ 3.95e+05  6.44e+05]\n",
      " [ 3.26e+05  2.19e+05]\n",
      " [ 2.22e+06  3.16e+06]\n",
      " [ 1.73e+05  7.64e+04]\n",
      " [ 2.22e+06  3.77e+06]\n",
      " [ 1.42e+05  4.84e+04]\n",
      " [ 1.32e+06  6.94e+05]\n",
      " [ 1.25e+06  7.79e+05]\n",
      " [ 1.81e+06  1.23e+06]\n",
      " [ 4.17e+05  2.76e+05]\n",
      " [ 1.75e+06  1.09e+06]\n",
      " [ 1.36e+06  6.72e+05]\n",
      " [ 2.02e+06  1.81e+06]\n",
      " [ 2.08e+06  1.05e+06]\n",
      " [ 2.70e+05  1.34e+05]\n",
      " [ 1.96e+06  2.48e+06]\n",
      " [ 4.73e+05  1.68e+03]\n",
      " [ 1.90e+06  1.16e+06]\n",
      " [ 2.37e+05  2.49e+05]\n",
      " [ 1.31e+06  6.28e+05]\n",
      " [ 1.86e+06  1.49e+06]\n",
      " [ 4.10e+05  5.37e+05]\n",
      " [ 1.38e+05  1.16e+05]\n",
      " [ 3.70e+05  5.84e+05]\n",
      " [-2.93e+04  6.30e+02]\n",
      " [ 2.17e+05  9.78e+04]\n",
      " [ 1.30e+04  1.58e+05]\n",
      " [ 2.94e+05  2.22e+05]\n",
      " [-1.98e+04  6.63e+01]\n",
      " [-5.43e+04  9.60e+02]\n",
      " [ 2.05e+06  2.22e+06]\n",
      " [-5.24e+04  6.44e+04]\n",
      " [ 1.45e+05  7.32e+04]\n",
      " [ 4.07e+05  5.50e+05]\n",
      " [ 2.03e+06  1.32e+06]\n",
      " [ 1.46e+06  7.92e+05]\n",
      " [ 1.92e+06  2.77e+06]\n",
      " [ 2.26e+06  1.05e+02]\n",
      " [ 4.85e+05  2.25e+02]\n",
      " [ 1.85e+06  1.48e+06]\n",
      " [ 2.88e+05  2.28e+05]\n",
      " [ 3.61e+04  1.65e+02]\n",
      " [ 9.61e+04  6.00e-02]\n",
      " [-1.79e+05  7.85e+04]\n",
      " [ 2.57e+05  9.91e+04]\n",
      " [ 1.63e+05  1.14e+05]\n",
      " [ 2.12e+05  6.99e+05]\n",
      " [ 2.41e+05  3.36e+05]\n",
      " [ 2.00e+05  2.84e+05]\n",
      " [-3.86e+04  3.62e+02]\n",
      " [ 2.08e+06  2.76e+06]\n",
      " [ 2.15e+06  2.38e+06]\n",
      " [ 2.56e+05  2.40e+05]\n",
      " [ 6.50e+04  6.33e+02]\n",
      " [ 1.69e+06  9.43e+05]\n",
      " [ 1.06e+06  7.36e+05]\n",
      " [ 1.51e+06  6.86e+01]\n",
      " [ 2.08e+04  1.17e+05]\n",
      " [ 3.38e+05  1.99e+05]\n",
      " [ 3.01e+04  8.01e+02]\n",
      " [-7.77e+03  9.50e+01]\n",
      " [ 4.38e+05  4.19e+05]\n",
      " [ 3.64e+05  5.18e+05]\n",
      " [ 2.10e+06  1.74e+06]\n",
      " [ 2.01e+05  6.59e+04]\n",
      " [ 8.62e+04  1.22e+02]\n",
      " [ 1.99e+06  2.02e+06]\n",
      " [ 1.70e+05  1.03e+05]\n",
      " [ 1.41e+06  7.38e+05]\n",
      " [ 2.27e+06  2.03e+06]\n",
      " [ 3.79e+05  2.66e+05]\n",
      " [ 4.34e+05  4.24e+05]\n",
      " [ 1.92e+05  1.30e+05]\n",
      " [ 2.16e+06  1.41e+06]\n",
      " [ 3.09e+05  2.65e+05]\n",
      " [ 7.12e+04  1.08e+03]\n",
      " [ 1.82e+06  1.50e+06]\n",
      " [ 1.75e+04  7.68e+02]\n",
      " [ 1.44e+06  2.54e+06]\n",
      " [-9.80e+04  2.63e+02]\n",
      " [ 1.80e+06  1.74e+06]\n",
      " [ 2.19e+06  3.23e+06]\n",
      " [ 1.91e+06  1.24e+06]\n",
      " [-7.65e+04  1.11e+03]\n",
      " [-4.18e+04  4.80e+02]\n",
      " [ 3.32e+05  2.34e+05]\n",
      " [ 3.18e+04  9.95e+04]\n",
      " [ 1.82e+05  2.38e+05]\n",
      " [ 2.23e+06  8.74e+05]\n",
      " [ 2.18e+06  3.23e+06]\n",
      " [ 1.33e+06  1.15e+06]\n",
      " [ 1.33e+06  7.34e+05]\n",
      " [ 1.93e+04  1.62e+05]\n",
      " [ 1.88e+06  1.80e+06]\n",
      " [ 1.32e+05  1.44e+05]\n",
      " [ 2.36e+05  1.38e+05]\n",
      " [ 1.21e+05  5.00e-02]\n",
      " [ 2.00e+06  1.64e+06]\n",
      " [ 4.89e+04  6.51e+02]\n",
      " [ 1.15e+05  7.60e-01]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50DZZy0UyhLi"
   },
   "source": [
    "## Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPagAOKDywV4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71936936890157"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.88 %\n",
      "Standard Deviation: 5.44 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = regressor, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multiple_linear_regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
